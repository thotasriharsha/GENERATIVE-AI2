{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2Ss8x2SmbtZoHKs5ldPul",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thotasriharsha/GENERATIVE-AI2/blob/main/2303A52159_week_3_ASS_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHn0ztBoAoSn"
      },
      "outputs": [],
      "source": [
        "Question 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 1: Find the value of x at which f(x) = 5x^4 + 3x^2 + 10 has minimum value\n",
        "\n",
        "def gradient_descent_1d(alpha=0.01, epsilon=1e-6, max_iter=10000):\n",
        "    def f_prime(x):\n",
        "        return 20 * x**3 + 6 * x  # Derivative of f(x)\n",
        "\n",
        "    x = 0.0  # Initial guess\n",
        "    for _ in range(max_iter):\n",
        "        grad = f_prime(x)\n",
        "        if abs(grad) < epsilon:\n",
        "            break\n",
        "        x -= alpha * grad\n",
        "    return x\n",
        "\n",
        "x_min = gradient_descent_1d()\n",
        "print(f\"Minimum value of f(x) occurs at x = {x_min}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lq25bKdoDriD",
        "outputId": "1839538c-4a31-458e-8343-d313e01e8824"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum value of f(x) occurs at x = 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2"
      ],
      "metadata": {
        "id": "4ALvG4JwEZA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Task 2: Find the values of x and y at which g(x, y) = 3x^2 + 5e^(-y) + 10 has minimum value\n",
        "\n",
        "def gradient_descent_2d(alpha=0.01, epsilon=1e-6, max_iter=10000):\n",
        "    def f_prime_x(x):\n",
        "        return 6 * x  # Partial derivative with respect to x\n",
        "\n",
        "    def f_prime_y(y):\n",
        "        return -5 * (2.718281828459045 ** (-y))  # Partial derivative with respect to y\n",
        "\n",
        "    x, y = 0.0, 0.0  # Initial guesses\n",
        "    for _ in range(max_iter):\n",
        "        grad_x = f_prime_x(x)\n",
        "        grad_y = f_prime_y(y)\n",
        "        if abs(grad_x) < epsilon and abs(grad_y) < epsilon:\n",
        "            break\n",
        "        x -= alpha * grad_x\n",
        "        y -= alpha * grad_y\n",
        "    return x, y\n",
        "\n",
        "x_min, y_min = gradient_descent_2d()\n",
        "print(f\"Minimum value of g(x, y) occurs at x = {x_min}, y = {y_min}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KqfrF6CD6br",
        "outputId": "5c2ae629-daac-426f-9343-7310d2615668"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum value of g(x, y) occurs at x = 0.0, y = 6.216917124174048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3"
      ],
      "metadata": {
        "id": "hwB6ibT-EdVi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Task 3: Find the value of x at which z(x) = 1 / (1 + e^(-x)) has minimum value\n",
        "\n",
        "def gradient_descent_sigmoid(alpha=0.01, epsilon=1e-6, max_iter=10000):\n",
        "    def z_prime(x):\n",
        "        exp_neg_x = 2.718281828459045 ** (-x)\n",
        "        return -exp_neg_x / ((1 + exp_neg_x) ** 2)  # Derivative of sigmoid function\n",
        "\n",
        "    x = 0.0  # Initial guess\n",
        "    for _ in range(max_iter):\n",
        "        grad = z_prime(x)\n",
        "        if abs(grad) < epsilon:\n",
        "            break\n",
        "        x -= alpha * grad\n",
        "    return x\n",
        "\n",
        "x_min_sigmoid = gradient_descent_sigmoid()\n",
        "print(f\"Minimum value of z(x) occurs at x = {x_min_sigmoid}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2GIHtNnEAV7",
        "outputId": "821ef83e-b976-4ed2-ee68-cf289de57f77"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum value of z(x) occurs at x = 4.510913300793877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4"
      ],
      "metadata": {
        "id": "VcfFeyE0Eft7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 4: Find the optimal values of M and C for minimizing SE = (ExpectedOutput - PredictedOutput)^2\n",
        "\n",
        "def gradient_descent_linear(alpha=0.01, epsilon=1e-6, max_iter=10000):\n",
        "    expected_outputs = [1, 2, 3, 4, 5]  # Example expected outputs\n",
        "    inputs = [1, 2, 3, 4, 5]  # Example inputs\n",
        "\n",
        "    def predicted_output(m, c, x):\n",
        "        return m * x + c\n",
        "\n",
        "    def se_grad_m(m, c):\n",
        "        return -2 * sum((e - predicted_output(m, c, x)) * x for e, x in zip(expected_outputs, inputs))\n",
        "\n",
        "    def se_grad_c(m, c):\n",
        "        return -2 * sum(e - predicted_output(m, c, x) for e, x in zip(expected_outputs, inputs))\n",
        "\n",
        "    m, c = 0.0, 0.0  # Initial guesses\n",
        "    for _ in range(max_iter):\n",
        "        grad_m = se_grad_m(m, c)\n",
        "        grad_c = se_grad_c(m, c)\n",
        "        if abs(grad_m) < epsilon and abs(grad_c) < epsilon:\n",
        "            break\n",
        "        m -= alpha * grad_m\n",
        "        c -= alpha * grad_c\n",
        "    return m, c\n",
        "\n",
        "m_opt, c_opt = gradient_descent_linear()\n",
        "print(f\"Optimal values are M = {m_opt}, C = {c_opt}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grxuJrRQEMm6",
        "outputId": "ae6b5436-ff69-4553-e265-d445b4accd43"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal values are M = 0.9999998375829822, C = 5.863769691679814e-07\n"
          ]
        }
      ]
    }
  ]
}